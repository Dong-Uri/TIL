(정리 도움받음)

#1

모빌리티 - 자율주행 개요 및 활용
자율주행 6단계
레벨 0[비자동화]: 운전자가 차량 제어를 전부 수행
레벨 1[운전자 보조]: 운전자가 직접 운전하고, 특정 주행모드에서 조향 또는 감/가속 중 하나만 수행
레벨 2[부분 자동화]: 운전자가 직접 운전하고, 특정 주행모드에서 시스템에 조향 및 감/가속 모두 수행
레벨 3[조건부 자동화]: 특정 주행모드에서 시스템이 차량 제어를 전부 수행하며, 운전자는 시스템 개입 요청 시에만 대체 수행
레벨 4[고등 자동화]: 특정 주행모드에서 시스템이 차량 제어를 전부 수행하며, 운전자는 해당 모드에서 개입 불필요
레벨 5[완전 자동화]: 모든 주행상황에서 시스템이 차량 제어를 전부 수행
SAE(미국 자동차 공학회) 정의, 업계 표준
레벨 2 이하 ADAS 시스템
레벨 3은 큰 전환점
운전자 중심에서 자동차 중심으로 전환
사고 발생시 법적 책임 제조사로
자율주행 기술 현황
2023년 레벨 3 상용화 시작 전망
자율주행 기술 개발 전략
빅테크 회사: 급진적 전략으로 레벨 4이상 자율주행 기술 개발
완성차 업체: 점진적 전략으로 레벨 1부터 순차적적 기술 개발
자율주행 프로세스
인지 + 판단 + 제어
인지: 주변 교통상황 감지
판단: 주행상황 판단 및 주행
제어: 차량의 조향 및 속도 제어
인지기술
차량 주변 상황 인식을 위한 센서 설계 및 제작, 신호처리 및 인식 알고리즘 기술
CAMERA, LiDAR, Radar, Ultrasonic 센서 등
고정밀 GPS 기술, 정밀지도 구축 등
차량에 탑재된 센서가 가지는 한계를 보완하기 위한 V2X 기술 및 구축 등
자율주행 센서
자율주행을 위해 다양한 센서 사용
서로 다른 센서로 보완
대표적인 센서들
CAMERA, LiDAR, Radar, Ultrasonic
센서 - CAMERA
개체 인지 및 위치 추정에 활용
텍스처 정보(색상, 문자)를 포함한 이미지, 영상 정보 제공
다양한 화각의 다수 카메라를 장착해 FOV 확보
고해상도, 저렴한 비용
악천후 및 조명 환경 변화에 취약, 정확한 거리 추정 불가
차선, 표지판 및 신호인식, 주변 차량 및 보행자 구별
다양한 형태로 발전 중
다기능 전방 카메라, 스테레오 카메라, 나이트 비전 카메라 등
Tesla Front Triple Camera Sensor
FOV 50° 150m - 주 카메라, 물체, 신호등, 표지판, 차선 등 인식
FOV 25° 250m - 주 카메라보다 멀리 있는 물체, 신호등, 표지판, 차선 등 인식
FOV 150° 60m - 끼어드는 차량, 좁은 커브길 차선 감지, 보행자/자전거, 정지선 신호등 등 인식
센서 - Radar
장애물 회피 및 충돌 감지에 사용
전자기파를 이용해 측정한 거리, 속도(상대속도) 정보 제공
근거리와 원거리에 대해 모두 측정 가능
눈, 비, 조명 등 외부 환경에 영향을 받지 않음
작은 물체 측정에 취약, 낮은 해상도
전파 도달 거리에 따라 분류
Short Range Radar - 근접 충돌, 주차 보조
Mid Range Radar - 주차 차선, 사각지역 감시
Long Range Radar - 전방 감시, ACC
장애물 유무, 거리, 방향, 상대속도 감지
정확한 물체 판별 불가
센서 - LiDAR
개체 인식 및 위치 추정에 사용
레이저를 이용해 고해상도의 정확한 3차원 정보 제공
대상체에 대한 반사도 정보 제공 (Intensity)
조명 환경 변화에 영향을 받지 않음
눈, 비, 안개 등 악천후에 민감하고 높은 비용
회전형에서 고정형 라이다 형태로 진화 중
낮은 가격 및 소형화 가능
고정형 라이다 여러 개 장착
Point Cloud
반사된 점들의 3차원 공간 속 데이터 집합
점들이 합쳐서 3차원 형상이나 객체 구분
각 점은 x, y, z 좌표 + intensity
Processing - LiDAR 데이터 Load
Downsampling - 중복 제거
Segmentation - 의미 단위로 구분
Clustering - 거리 기반 군집화
Bounding Box - 객체 위치 표시
Awesome LiDAR : https://github.com/szenergy/awesome-lidar
영문 자료지만, LiDAR 관련 내용이 잘 정리되어 있음
센서 - Ultrasonic
장애물 회피 및 충돌 감지에 활용
초음파를 이용해 측정한 거리 정보 제공
근거리 (대략 5m 이내) 한정 측정 가능
눈, 비, 조명 등 외부 환경에 영향을 받지 않음
매우 낮은 해상도
센서 비교
센서마다 특장점 존재
CAMERA: 유일하게 색상, 문자 인식
Radar: 악천후 강함
LiDAR: 형태 및 3차원 데이터
하나의 센서보다는 여러 센서 조합 사용
CAMERA + LiDAR (or Radar)
센서 퓨전 (CAMEAR + LiDAR)
다양한 객체의 형태와 색상 인식 가능한 카메라와 정밀한 거리 측정이 가능한 라이다 결합
영상을 통해 수집되는 객체의 세부 정보를 라이다 3D 포인트 클라우드와 통합
GPS
차량의 위치 추정에 필요
위성 신호를 이용해 지구좌표계에 따른 절대 위치 정보 제공 (위도, 경도, 고도)
지하, 터널, 도심(빌딩숲) 등에서 음영 지역 발생
일반적인 GPS는 수 m 오차, 최근 정밀 GPS 기술은 수십 cm 내 정확도
IMU
차량의 위치 추정에 필요
6축 또는 9축 (가속도, 지자기, 자이로) 정보를 제공
추측 항법을 통해 이동 거리 및 방향 추정 가능
외부 환경에 영향을 받지 않지만, 시간에 따른 누적 오차 발생
정밀지도 (HD 맵)
자율주행 차량을 위한 다양한 도로 정보가 정밀하게 기록되어 있는 지도
위치 추정, 경로 계획, 개체 인지에 모두 사용
도로 규칙 정보, 구조물 형상 정보, 실시간 교통 정보, 센서 데이터 등
일반적으로 자율주행은 20cm 이내 오차 허용
정밀지도 구축에 많은 비용이 들고, 지속적인 업데이트 필요
정밀지도 구축 자동화 중요
네이버, 카카오, 구글, 애플, 앙마존 등 많은 기업들이 정밀지도 구축에 관심
V2X (Vehicle to Everything)
통신을 통해 다른 차량 및 도로 등 인프라가 구축된 사물과 정보 교환
V2V, V2I, V2P 등
인지범위 확대 - 차량에 장착된 센서를 넘어서 통신을 통해 주변의 교통 정보 획득
통신 지역시간 매우 중요 - 5G 기대
LTE: 지연시간 10ms 이상
5G: 지연시간 1ms 이내
정리
자율주행에 사용되는 센서와 특장점 및 서로 보완을 위한 센서 퓨전
CAMERA, Radar, LiDAR, Ultrasonic
정확한 차량 위치 확인을 위한 GPS, IMU 센서와 정밀지도
인지범위 확대와 로컬 센서의 한계를 보완하기 위한 V2X 기술

#2

자율주행
자율주행 6단계
자율주행 기술 현황
인지기술
자율주행 센서
센서 - Camera
센서 - Radar
센서 - Ultrasonic
센서 비교
센서 퓨전(Camera + LiDAR)
GPS
IMU
정밀지도(HD 맵)
V2X(Vehicle to Everything)
정리
자율주행 6단계
SAE(미국 자동차 공학회) 정의, 업계 표준
레벨2이하 ADAS 시스템
레벨3은 큰 전화점
운전자 중심에서 자동차 중심으로 전환
사고 발생시 법적 책임 제조사로
자율주행 기술 현황
2023년 레벨3 상용화 시작 전망
자율주행 기술 개발 전략
빅 테크 회사 : 급진적 전략으로 레벨4이상 자율주행 기술 개발
완성차 업체 : 점진적 전략으로 레벨1부터 순차적으로 개발
인지기술
차량 주변 상황 인식을 위한 센서 설계 및 제작, 신호처리 및 인식 알고리즘 기술
Camera, LiDAR, Ultrasonic센서 등
고정밀 GPS 기술, 정밀지도 구축 등
차량에 탑재된 센서가 가지는 한계를 보완하기 위한 V2X 기술 및 구축 등
자율주행 센서
자율주행을 위한 다양한 센서 사용
서로 다른 센서로 보완
대표적인 센서들
Camera, Radar, LiDAR, Ultrasonic
센서 - Camera
개체 인지 및 위치 추정에 활용
텍스처 정보(색상, 문자)를 포함한 이미지, 영상 정보 제공
다양한 화각의 다수 카메라를 장착해 FOV 확보
고해상도, 저렴한 비용
악천후 및 조명 환경 변화에 취약, 정확한 거리 추정 불가
차선, 표지판 및 신호 인식, 주변 차량 및 보행자 구별
다양한 형태로 발전 중
다기능 전방카메라, 스테레오 카메라, 나이트비전 카메라 등
Tesla Front Triple Camera Sensor
FOV 50도 150m - 주 카메라, 물체-신호등-표지판-차선 등 인식
FOV 25도 250m - 주 카메라보다 멀리 있는 물체-신호등-표지판-차선 등 인식
FOV 150도 60m - 끼어드는 차량, 좁은 커브길 차선 감지, 보행자/자전거, 정지선 신호등 등 인식
센서 - Radar
장애물 회피 및 충돌 감지에 활용
전자기파를 이용해 측정한 거리, 속도(상대속도) 정보 제공
근거리와 원거리에 대해 모두 측정 가능
눈, 비, 조명 등 외부 환경에 영향을 받지 않음
작은 물체 측정에 취약, 낮은 해상도
전파 도달 거리에 따라 분류
Short Range Radar - 근접 충돌, 주차보조
Mid Range Radar - 주변 차선, 사각지역 감시
Long Range Radar - 전방 감시, ACC
장애물 유무, 거리, 방향, 상대속도 감지
정확한 물체 판별 불가
센서 - LiDAR
개체 인식 및 위치 추정에 활용
레이저를 이용해 고해상도의 정확한 3차원 정보 제공
대상체에 대한 반사도 정보 제공(Intensity)
조명 환경 변화에 영향을 받지 않음
눈, 비, 안개 등 악천후에 민감하고, 높은 비용
회전형에서 고정형 라이다 형태로 진화 중
낮은 가격 및 소형화 가능
고정형 라이다 여러개 장착
Point Cloud
반사된 점들의 3차원 공간 속 데이터 집합
점들이 합쳐서 3차원 형상이나 객체 구분
각 점은 x, y, z 좌표 + intensity
Processing - LiDAR 데이터 Load
Downsampling - 중복 제거
Segmentation - 의미 단위 구분
Clustering - 거리 기반 군집화
Bounding Box - 객체 위치 표시
Awesome LiDAR - https://github.com/szenergy/awesome-lidar
영문 자료지만 LiDAR 관련 내용이 잘 정리되어 있음
센서 - Ultrasonic
장애물 회피 및 충돌 감지에 활용
초음파를 이용해 측정한 거리 정보 제공
근거리(대략 5m 이내) 한정 측정 가능
눈, 비, 조명 등 외부 환경에 영향을 받지 않음
매우 낮은 해상도
센서비교
센서마다 특장점 존재
Camera : 유일하게 색상, 문자 인식
Radar : 악천후 강함
LiDAR : 형태 및 3차원 데이터
하나의 센서보다는 여러 센서 조합 사용
Camera + LiDAR(or Radar)
센서 퓨전(Camera + LiDAR)
다양한 객체의 형태와 색상 인식 가능한 카메라와 정밀한 거리 측정이 가능한 라이다 결합
영상을 통해 수집되는 객체의 세부 정보를 라이다 3D 포인트 클라우드와 통합
GPS
차량의 위치 추정에 필요
위성 신호를 이용해 지구 좌표계에 따른 절대 위치 정보 제공(위도, 경도, 고도)
지하/터널/도심(빌딩숲) 등에서 음영 지역 발생
일반적인 GPS는 수 m 오차, 최근 정밀 GPS 기술은 수십 cm 내 정확도
IMU
차량의 위치 추정에 필요
6축 또는 9축(가속도, 지자기, 자이로) 정보를 제공
추측 항법을 통해 이동 거리 및 방향 추정 가능
외부 환경에 영향을 받지 않지만, 시간에 따른 누적 오차 발생
정밀지도(HD 맵)
자율주행 차량을 위한 다양한 도로 정보가 정밀하게 기록되어 있는 지도
위치 추정, 경로 계획, 개체 인지에 모두 사용
도로 규칙 정보, 구조물 형상 정보, 실시간 교통 정보, 센서 데이터 등
일반적으로 자율주행은 20cm 이내 오차 허용
정밀지도 구축에 많은 비용이 들고 지속적인 업데이트가 필요
정밀지도 구축 자동화 중요
네이버, 카카오, 구글, 애플, 아마존 등 많은 기업들이 정밀지도 구축에 관심
V2X(Vehicle to Everything)
통신을 통해 다른 차량 및 도로 등 인프라가 구축된 사물과 정보 교환
V2V, V2I, V2P 등
인지범위 확대 - 차량에 장착된 센서를 넘어서 통신을 통해 주변의 교통 정보 획득
통신 지연시간 매우 중요 - 5G 기대
LTE : 지연시간 10ms 이상 / 5G : 지연시간 1ms 이내
통신이기 때문에 보안 이슈는 항상 따라 다님
정리
자율주행에 사용되는 센서와 특장점 및 서로 보완을 위한 센서 퓨전
Camera, Radar, LiDAR, Ultrasonic
정확한 차량 위치 확인을 위한 GPS, IMU 센서와 정밀지도
인지범위 확대와 로컬센서의 한계를 보완하기 위한 V2X 기술
