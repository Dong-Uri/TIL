- Convolution 연산

  - 지금까지 배운 다층신경망(MLP)은 각 뉴런들이 선형모델과 활성함수로 모두 연결된 (fully connected) 구조
  - Convolution 연산은 이와 달리 커널(kernel)을 입력벡터 상에서 움직여가면서 선형모델과 합성함수가 적용되는 구조
  - Convolution 연산의 수학적인 의미는 신호(signal)를 커널을 이용해 국소적으로 증폭 또는 감소시켜서 정보를 추출 또는 필터링하는 것
  - 커널은 정의역 내에서 움직여도 변하지 않고(translation invariant) 주어진 신호에 국소적(local)으로 적용

- 다양한 차원에서의 Convolution

  - Convolution 연산은 1차원뿐만 아니라 다양한 차원에서 계산 가능

- 2차원 Convolution 연산

  - 2D-Conv 연산은 이와 달리 커널(kernel)을 입력벡터 상에서 움직여가면서 선형모델과 합성함수가 적용되는 구조
  - 입력 크기르 (H,V), 커널 크기를 (KH,KW), 출력크기를 (OH,OW)라 하면 출력 크기는 다음과 같이 계산
    - OH = H - KH + 1
    - OW = W - KW + 1
  - 채널이 여러개인 2차원 입력의 경우 2차원 Convolution을 채널 개수만큼 적용
    - 3차원부터는 행렬이 아닌 텐서라 부름
  - 텐서를 직육면체 블록으로 이해하면 좀 더 이해하기 쉬움
    - 커널을 OC개 사용하면 출력도 텐서가 됨

- Convolution 연산의 역전파

  - Convolution 연산은 커널이 모든 입력데이터에 공통으로 적용되기 때문에 역전파를 계산할 때도 convolution 연산이 나오게 됨
